{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeedForward_NN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5D7q0kjyBF6np3Oc4QLC/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talibaisi/MachineLearning/blob/main/FeedForward_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXRGBbs1xilZ",
        "outputId": "3776c1f3-a6a7-4cb3-e0e3-ff9d5693d9e5"
      },
      "source": [
        "import keras\r\n",
        "# Load libraries\r\n",
        "import numpy as np\r\n",
        "from keras.datasets import imdb\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "# Set random seed\r\n",
        "np.random.seed(0)\r\n",
        "# Set the number of features we want\r\n",
        "number_of_features = 1000\r\n",
        "# Load data and target vector from movie review data\r\n",
        "(data_train, target_train), (data_test, target_test) = imdb.load_data(\r\n",
        "num_words=number_of_features)\r\n",
        "# Convert movie review data to one-hot encoded feature matrix\r\n",
        "tokenizer = Tokenizer(num_words=number_of_features)\r\n",
        "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\r\n",
        "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\r\n",
        "# Start neural network\r\n",
        "network = models.Sequential()\r\n",
        "# Add fully connected layer with a ReLU activation function\r\n",
        "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(\r\n",
        "number_of_features,)))\r\n",
        "# Add fully connected layer with a ReLU activation function\r\n",
        "network.add(layers.Dense(units=16, activation=\"relu\"))\r\n",
        "# Add fully connected layer with a sigmoid activation function\r\n",
        "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\r\n",
        "# Compile neural network\r\n",
        "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\r\n",
        "optimizer=\"rmsprop\", # Root Mean Square Propagation\r\n",
        "metrics=[\"accuracy\"]) # Accuracy performance metric"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNnXyWvoQTgU",
        "outputId": "b3cd386b-03ce-4e02-a338-676fbaa6965a"
      },
      "source": [
        "# Train neural network\r\n",
        "history = network.fit(features_train, # Features\r\n",
        "target_train, # Target vector\r\n",
        "epochs=3, # Number of epochs\r\n",
        "verbose=1, # Print description after each epoch\r\n",
        "batch_size=100, # Number of observations per batch\r\n",
        "validation_data=(features_test, target_test))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "250/250 [==============================] - 2s 4ms/step - loss: 0.5631 - accuracy: 0.6987 - val_loss: 0.3391 - val_accuracy: 0.8576\n",
            "Epoch 2/3\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.8654 - val_loss: 0.3284 - val_accuracy: 0.8615\n",
            "Epoch 3/3\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3050 - accuracy: 0.8757 - val_loss: 0.3279 - val_accuracy: 0.8610\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}